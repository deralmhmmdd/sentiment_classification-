{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimnet Analyst Classification\n",
    "##### `Sentiment atau emosi yang diungkapkan dalam teks bersifat positif, negatif dan netral`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengimpor Data TSV\n",
    "##### Struktur Data TSV File TSV `terdiri dari beberapa baris` di mana setiap baris merepresentasikan satu `record atau entri data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi untuk set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk set seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(27)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi Untuk Membersihkan Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    return text \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi Untuk Normalisasi Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_text(text):\n",
    "    replacements = {\n",
    "        'tdk': 'tidak', 'dmn': 'dimana', 'cpt': 'cepat', 'ga': 'tidak', 'enggak': 'tidak',\n",
    "        'ngga': 'tidak', 'gak': 'tidak', 'bgt': 'banget', 'bgd': 'banget', 'bnyk': 'banyak',\n",
    "        'bgtu': 'begitu', 'dgn': 'dengan', 'hrs': 'harus', 'knp': 'kenapa', 'lgsg': 'langsung',\n",
    "        'ngerti': 'mengerti', 'pake': 'pakai', 'sangat2': 'sangat', 'sukak': 'suka', 'syg': 'sayang',\n",
    "        'ttg': 'tentang', 'utk': 'untuk', 'wkt': 'waktu', 'yaa': 'ya', 'bgitu': 'begitu', 'ak': 'aku',\n",
    "        'kau': 'kamu', 'saya': 'aku', 'anda': 'kamu', 'kami': 'kita', 'kalian': 'kamu', 'dirimu': 'kamu',\n",
    "        'dirinya': 'dia', 'diriku': 'aku'\n",
    "    }\n",
    "    for key, value in replacements.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membaca dan Memproses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dan memproses data\n",
    "df_train = pd.read_csv('train_preprocess.tsv', sep='\\t', header=None)\n",
    "df_valid = pd.read_csv('valid_preprocess.tsv', sep='\\t', header=None)\n",
    "df_test = pd.read_csv('test_preprocess.tsv', sep='\\t', header=None)\n",
    "\n",
    "df_train.columns = ['review_text', 'category']\n",
    "df_valid.columns = ['review_text', 'category']\n",
    "df_test.columns = ['review_text', 'category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text  category\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
       "...                                                  ...       ...\n",
       "10995                                       tidak kecewa  positive\n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...  positive\n",
       "10997        hormati partai-partai yang telah berkoalisi   neutral\n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...  negative\n",
       "10999  meskipun sering belanja ke yogya di riau junct...  positive\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengonversi label teks menjadi numberik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_mapping = {'positive': 1, 'negative': 0,'neutral': 2}\n",
    "df_train['category'] = df_train['category'].map(label_mapping)\n",
    "df_valid['category'] = df_valid['category'].map(label_mapping)\n",
    "df_test['category'] = df_test['category'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konversi kolom 'category' ke tipe data numberik dan pastikan tidak ada yang NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi kolom 'category' ke tipe data numerik dan pastikan tidak ada NaN\n",
    "df_train = df_train.dropna(subset=['category'])\n",
    "df_valid = df_valid.dropna(subset=['category'])\n",
    "df_test = df_test.dropna(subset=['category'])\n",
    "\n",
    "df_train['category'] = df_train['category'].astype(int)\n",
    "df_valid['category'] = df_valid['category'].astype(int)\n",
    "df_test['category'] = df_test['category'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text  category\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...         1\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...         2\n",
       "2      lokasi strategis di jalan sumatera bandung . t...         1\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...         1\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...         0\n",
       "...                                                  ...       ...\n",
       "10995                                       tidak kecewa         1\n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...         1\n",
       "10997        hormati partai-partai yang telah berkoalisi         2\n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...         0\n",
       "10999  meskipun sering belanja ke yogya di riau junct...         1\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengambil sampel data menjadi 1000 sampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    11000\n",
       "category       11000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    500\n",
       "category       500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    1260\n",
       "category       1260\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sampled = df_train.sample(n=500, random_state=27)\n",
    "df_valid_sampled = df_valid.sample(n=500, random_state=27)\n",
    "df_test_sampled = df_test.sample(n=500, random_state=27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membersihkan dan Normalisasi Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membersihkan dan normalisasi teks\n",
    "df_train_sampled['review_text'] = df_train_sampled['review_text'].apply(lambda x: clean_text(str(x).lower()))\n",
    "df_valid_sampled['review_text'] = df_valid_sampled['review_text'].apply(lambda x: clean_text(str(x).lower()))\n",
    "df_test_sampled['review_text'] = df_test_sampled['review_text'].apply(lambda x: clean_text(str(x).lower()))\n",
    "\n",
    "df_train_sampled['review_text'] = df_train_sampled['review_text'].apply(normalize_text)\n",
    "df_valid_sampled['review_text'] = df_valid_sampled['review_text'].apply(normalize_text)\n",
    "df_test_sampled['review_text'] = df_test_sampled['review_text'].apply(normalize_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cetak Hasil Pembersihkan dan Normalisasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Pembersihan dan Normalisasi Data Train:\n",
      "                                            review_text  category\n",
      "5053                                        tidaku rapi         0\n",
      "6436  makuan di saung di tentidakuh sawah makuanan n...         1\n",
      "709   resto ini bekas tempat penggertidakujian kayu ...         1\n",
      "7844  jika sedang di cihampelas dan cari oleholeh co...         1\n",
      "5584  pada bulan oktober lalu aku dan teman aku maku...         1\n",
      "\n",
      "Hasil Pembersihan dan Normalisasi Data Valid:\n",
      "                                            review_text  category\n",
      "556   menemukan tempat makuan ini secara tidaku sent...         1\n",
      "1237  tempat nya nyaman dentidakun pemkamuntidakun k...         1\n",
      "747                                  jokowi kerja nyata         1\n",
      "329   dedi mulyadi dan ridwan kital diangtidakup kep...         2\n",
      "869   nah di sini letaku permasalahan nya bang demok...         0\n",
      "\n",
      "Hasil Pembersihan dan Normalisasi Data Test:\n",
      "                                           review_text  category\n",
      "37   aku sudah berhasil transakusi sesuai nominal t...         0\n",
      "486  baiknya orang yang dikasih kekuasaan di indone...         2\n",
      "421  tidaku pernah kecewa sama model sepatu nike se...         1\n",
      "23   luar biasa kecewa santidakut dentidakun aplika...         0\n",
      "424  sandy shandoro tidaku pernah tidakutidakul bik...         1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Hasil Pembersihan dan Normalisasi Data Train:\")\n",
    "print(df_train_sampled.head())\n",
    "\n",
    "print(\"\\nHasil Pembersihan dan Normalisasi Data Valid:\")\n",
    "print(df_valid_sampled.head())\n",
    "\n",
    "print(\"\\nHasil Pembersihan dan Normalisasi Data Test:\")\n",
    "print(df_test_sampled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menginisialisasi Tokenizer BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi Untuk Tokenisasi dan Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_and_pad(sentences, max_length=64):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,                      # Kalimat yang akan ditokenisasi\n",
    "            add_special_tokens=True,   # Tambahkan '[CLS]' dan '[SEP]'\n",
    "            max_length=max_length,     # Padding & truncation length\n",
    "            padding='max_length',      # Pad ke max_length\n",
    "            return_attention_mask=True, # Return attention mask\n",
    "            return_tensors='pt',       # Return pytorch tensors\n",
    "            truncation=True            # Aktifkan truncation\n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Konversi lists ke tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisasi dan Padding Untuk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_inputs, train_masks = tokenize_and_pad(df_train_sampled['review_text'])\n",
    "valid_inputs, valid_masks = tokenize_and_pad(df_valid_sampled['review_text'])\n",
    "test_inputs, test_masks = tokenize_and_pad(df_test_sampled['review_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekstraksi Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_labels = torch.tensor(df_train_sampled['category'].values).long()\n",
    "valid_labels = torch.tensor(df_valid_sampled['category'].values).long()\n",
    "test_labels = torch.tensor(df_test_sampled['category'].values).long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Membuat TensorDataset\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=16, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inisialisasi model BERT untuk klasifikasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menentukan Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inisialisasi Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi Evaluasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device).long()  # Ubah ke tipe data long\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, b_labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean()\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menentukan Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pelatihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.9113919660449028\n",
      "Validation Loss: 0.7681390661746264, Validation Accuracy: 0.625\n",
      "Average Training Loss: 0.719468230381608\n",
      "Validation Loss: 0.7050008112564683, Validation Accuracy: 0.708984375\n",
      "Average Training Loss: 0.5834710355848074\n",
      "Validation Loss: 0.6857857443392277, Validation Accuracy: 0.693359375\n",
      "Average Training Loss: 0.4515790930017829\n",
      "Validation Loss: 0.6656732615083456, Validation Accuracy: 0.736328125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "for epoch in range(4):  # Lakukan 4 epoch\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device).long()  # Ubah ke tipe data long\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Average Training Loss: {avg_train_loss}\")\n",
    "\n",
    "    # Evaluasi\n",
    "    eval_loss, eval_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "    print(f\"Validation Loss: {eval_loss}, Validation Accuracy: {eval_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan Model Setelah Pelatihan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model setelah pelatihan\n",
    "torch.save(model.state_dict(), 'bert_sentiment_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install flask transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Inisialisasi Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Inisialisasi tokenizer dan model\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# Muat model yang telah dilatih\n",
    "model.load_state_dict(torch.load('bert_sentiment_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Menentukan device (CPU atau GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Fungsi untuk tokenisasi dan padding\n",
    "def tokenize_and_pad(sentences, max_length=64):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sentences,                      # Kalimat yang akan ditokenisasi\n",
    "        add_special_tokens=True,        # Tambahkan '[CLS]' dan '[SEP]'\n",
    "        max_length=max_length,          # Padding & truncation length\n",
    "        padding='max_length',           # Pad ke max_length\n",
    "        return_attention_mask=True,     # Return attention mask\n",
    "        return_tensors='pt',            # Return pytorch tensors\n",
    "        truncation=True                 # Aktifkan truncation\n",
    "    )\n",
    "    \n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
    "    \n",
    "    return input_ids, attention_mask\n",
    "\n",
    "# Mapping kategori label ke teks\n",
    "label_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "\n",
    "# Endpoint untuk klasifikasi sentimen\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Mendapatkan input teks dari request\n",
    "    data = request.json\n",
    "    text = data.get('text')\n",
    "    \n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "    \n",
    "    # Tokenisasi dan padding input teks\n",
    "    input_ids, attention_mask = tokenize_and_pad(text)\n",
    "\n",
    "    # Lakukan prediksi\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Mendapatkan prediksi label\n",
    "    preds = torch.argmax(logits, dim=1).flatten()\n",
    "    sentiment = label_mapping[preds.item()]\n",
    "\n",
    "    # Mengembalikan hasil dalam format JSON\n",
    "    return jsonify({\"output\": sentiment})\n",
    "\n",
    "# Menjalankan Flask app\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
